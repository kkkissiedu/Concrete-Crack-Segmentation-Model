{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5162de",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a67d33",
   "metadata": {},
   "source": [
    "# Model Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 50\n",
    "image_height = 256\n",
    "image_width = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56675dd7",
   "metadata": {},
   "source": [
    "# Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60272e14",
   "metadata": {},
   "source": [
    "# U-net Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dcd07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding = 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "\n",
    "\n",
    "class Attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(Attention_block,self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        #Encoding Layers\n",
    "        self.encoder1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.encoder2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.encoder3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.encoder4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "\n",
    "        #Decoding Layers\n",
    "        self.decoder1 = nn.ConvTranspose2d(1024, 512, kernel_size = 2, stride = 2)\n",
    "        self.att1 = Attention_block(F_g = 512, F_l = 512, F_int = 256)\n",
    "        self.conv1 = DoubleConv(1024, 512) \n",
    "\n",
    "        self.decoder2 = nn.ConvTranspose2d(512, 256, kernel_size = 2, stride = 2)\n",
    "        self.att2 = Attention_block(F_g = 256, F_l = 256, F_int = 128)\n",
    "        self.conv2 = DoubleConv(512, 256) \n",
    "\n",
    "        self.decoder3 = nn.ConvTranspose2d(256, 128, kernel_size = 2, stride = 2)\n",
    "        self.att3 = Attention_block(F_g = 128, F_l = 128, F_int = 64)\n",
    "        self.conv3 = DoubleConv(256, 128) \n",
    "\n",
    "        self.decoder4 = nn.ConvTranspose2d(128, 64, kernel_size = 2, stride = 2)\n",
    "        self.conv4 = DoubleConv(128, 64) \n",
    "        \n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        pool1 = self.pool1(enc1)\n",
    "\n",
    "        enc2 = self.encoder2(pool1)\n",
    "        pool2 = self.pool2(enc2)\n",
    "\n",
    "        enc3 = self.encoder3(pool2)\n",
    "        pool3 = self.pool3(enc3)\n",
    "\n",
    "        enc4 = self.encoder4(pool3)\n",
    "        pool4 = self.pool4(enc4)\n",
    "\n",
    "        bottleneck = self.bottleneck(pool4)\n",
    "\n",
    "        dec1 = self.decoder1(bottleneck)\n",
    "        att_enc4 = self.att1(g = dec1, x = enc4)\n",
    "        dec1 = torch.cat((att_enc4, dec1), dim=1) \n",
    "        dec1 = self.conv1(dec1)\n",
    "        \n",
    "        dec2 = self.decoder2(dec1)\n",
    "        att_enc3 = self.att2(g = dec2, x = enc3)\n",
    "        dec2 = torch.cat((att_enc3, dec2), dim=1)\n",
    "        dec2 = self.conv2(dec2)\n",
    "        \n",
    "        dec3 = self.decoder3(dec2)\n",
    "        att_enc2 = self.att3(g = dec3, x = enc2)\n",
    "        dec3 = torch.cat((att_enc2, dec3), dim=1)\n",
    "        dec3 = self.conv3(dec3)\n",
    "        \n",
    "        dec4 = self.decoder4(dec3)\n",
    "        dec4 = torch.cat((enc1, dec4), dim=1)\n",
    "        dec4 = self.conv4(dec4)\n",
    "        \n",
    "        out = self.final(dec4)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcec65",
   "metadata": {},
   "source": [
    "# Dataset Class and Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959112e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrackSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        all_files = os.listdir(data_dir)\n",
    "        image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        self.images = sorted([f for f in all_files if f.lower().endswith(image_extensions) and '_mask' not in f])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.images[index]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        base_name = os.path.splitext(img_name)[0]\n",
    "        mask_name = f\"{base_name}_mask.png\"\n",
    "        mask_path = os.path.join(self.data_dir, mask_name)\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {img_path}\")\n",
    "        if mask is None:\n",
    "            raise ValueError(f\"Could not load mask: {mask_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask.unsqueeze(0)\n",
    "    \n",
    "\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(image_height, image_width),\n",
    "    A.Rotate(limit=35, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.OneOf([\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.5),\n",
    "        A.MotionBlur(p=0.5),\n",
    "    ], p=0.4),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_tf = A.Compose([\n",
    "    A.Resize(image_height, image_width),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c297b68",
   "metadata": {},
   "source": [
    "# Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= CrackSegmentationDataset('./data/train', transform = train_tf)\n",
    "val_dataset = CrackSegmentationDataset('./data/valid', transform = val_tf)\n",
    "test_dataset = CrackSegmentationDataset('./data/test', transform = val_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 0, pin_memory = False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False, num_workers = 0, pin_memory = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False, num_workers = 0, pin_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51dbf3e",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13a8541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = torch.sigmoid(preds)\n",
    "        \n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (preds * targets).sum()\n",
    "        dice_union = preds.sum() + targets.sum()\n",
    "        \n",
    "        dice = (2. * intersection + self.smooth) / (dice_union + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "def dice_coefficient_binary(preds, targets, smooth=1e-6):\n",
    "    with torch.no_grad():\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = (preds > 0.5).float() \n",
    "        targets = targets.float()\n",
    "        \n",
    "        intersection = (preds * targets).sum()\n",
    "        dice_union = preds.sum() + targets.sum()\n",
    "        \n",
    "        dice = (2. * intersection + smooth) / (dice_union + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "bce_criterion = nn.BCEWithLogitsLoss()\n",
    "dice_criterion = DiceLoss()\n",
    "\n",
    "def combined_loss(preds, targets):\n",
    "    alpha = 0.5\n",
    "    return alpha * bce_criterion(preds, targets) + (1 - alpha) * dice_criterion(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c178b5",
   "metadata": {},
   "source": [
    "# Training and Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max',           \n",
    "    patience=5      \n",
    ")\n",
    "\n",
    "\n",
    "#Training Loop\n",
    "best_dice = -1.0\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc = f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        images, masks = images.to(device), masks.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = combined_loss(preds, masks)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "\n",
    "    val_dice_score = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device).float()\n",
    "            preds = model(images)\n",
    "            val_dice_score += dice_coefficient_binary(preds, masks)\n",
    "        \n",
    "    val_dice_score /= len(val_loader)\n",
    "    scheduler.step(val_dice_score)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Dice: {val_dice_score:.4f}\")\n",
    "        \n",
    "    if val_dice_score > best_dice:\n",
    "        best_dice = val_dice_score\n",
    "        torch.save(model.state_dict(), \"checkpoints/best_model_binary.pth\")\n",
    "        print(f\"==> Saved new best model with Dice Score: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cb3b0",
   "metadata": {},
   "source": [
    "# Visualizing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9928b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Background\", \"Crack\"]\n",
    "class_colors = [[0, 0, 0], [255, 0, 0]]\n",
    "cmap = ListedColormap(np.array(class_colors[1:])/255.0)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "model.load_state_dict(torch.load('checkpoints/best_model_binary.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs, masks = next(iter(test_loader))\n",
    "    imgs, masks = imgs.to(device), masks.to(device)\n",
    "\n",
    "    preds_logits = model(imgs)\n",
    "\n",
    "    preds = torch.sigmoid(preds_logits)\n",
    "    preds = (preds > 0.5).float()\n",
    "\n",
    "    fig, axes = plt.subplots(batch_size, 4, figsize=(18, batch_size * 4))\n",
    "    fig.suptitle(\"Model Predictions vs. Ground Truth\", fontsize=20)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img_np = imgs[i].cpu().permute(1, 2, 0).numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img_np = std * img_np + mean\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "\n",
    "        # 1. Input Image\n",
    "        axes[i, 0].imshow(img_np)\n",
    "        axes[i, 0].set_title(\"Input Image\")\n",
    "\n",
    "        # 2. Ground Truth\n",
    "        axes[i, 1].imshow(masks[i].squeeze(0).cpu(), cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 1].set_title(\"Ground Truth\")\n",
    "\n",
    "        # 3. Predicted Mask\n",
    "        axes[i, 2].imshow(preds[i].squeeze(0).cpu(), cmap='gray', vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title(\"Predicted Mask\")\n",
    "\n",
    "        # 4. Overlay\n",
    "        pred_mask_rgb = np.zeros_like(img_np)\n",
    "        pred_mask_squeezed = preds[i].squeeze(0).cpu().numpy()\n",
    "        pred_mask_rgb[pred_mask_squeezed == 1] = [1, 0, 0]\n",
    "\n",
    "        img_uint8 = (img_np * 255).astype(np.uint8)\n",
    "        mask_uint8 = (pred_mask_rgb * 255).astype(np.uint8)\n",
    "\n",
    "        overlay = cv2.addWeighted(img_uint8, 0.6, mask_uint8, 0.4, 0)\n",
    "        axes[i, 3].imshow(overlay)\n",
    "        axes[i, 3].set_title(\"Overlay\")\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        ax.axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "    legend_elements = [Patch(facecolor=np.array(c)/255.0, label=l) for c, l in zip(class_colors, class_labels)]\n",
    "    fig.legend(handles=legend_elements, loc=\"lower center\", ncol=len(class_labels), frameon=False)\n",
    "    plt.savefig(\"predictions_visualization_binary.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Saved visualization as 'predictions_visualization_binary.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ea606",
   "metadata": {},
   "source": [
    "# Model Performance on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf06b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "total_test_dice = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, masks in tqdm(test_loader, desc=\"Testing...\"):\n",
    "        imgs, masks = imgs.to(device), masks.to(device).float()\n",
    "        \n",
    "        preds = model(imgs)\n",
    "\n",
    "        loss = combined_loss(preds, masks)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        dice_score = dice_coefficient_binary(preds, masks)\n",
    "        total_test_dice += dice_score\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "avg_test_dice = total_test_dice / len(test_loader)\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Dice Score: {avg_test_dice:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
